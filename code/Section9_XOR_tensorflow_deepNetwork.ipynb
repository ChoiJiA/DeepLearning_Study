{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Tensorflow DeepNetwork\n",
    "- XOR : 서로 같은값이면 0, 서로 다른값이면 1이 나오는 알고리즘. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  # XOR with logistic regression(Accuracy=50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.88754326 [[0.7863567 ]\n",
      " [0.66282606]]\n",
      "100 0.6957384 [[0.23303682]\n",
      " [0.16537338]]\n",
      "200 0.69428164 [[0.14686331]\n",
      " [0.1107122 ]]\n",
      "300 0.6936611 [[0.09652315]\n",
      " [0.07720935]]\n",
      "400 0.6933805 [[0.06380114]\n",
      " [0.05348312]]\n",
      "500 0.69325316 [[0.04234112]\n",
      " [0.03682906]]\n",
      "600 0.6931954 [[0.02819199]\n",
      " [0.02524736]]\n",
      "700 0.6931691 [[0.0188217 ]\n",
      " [0.01724866]]\n",
      "800 0.6931572 [[0.01259338]\n",
      " [0.01175304]]\n",
      "900 0.6931517 [[0.00844097]\n",
      " [0.00799206]]\n",
      "1000 0.69314927 [[0.00566577]\n",
      " [0.00542596]]\n",
      "1100 0.69314814 [[0.00380733]\n",
      " [0.00367921]]\n",
      "1200 0.69314766 [[0.0025608 ]\n",
      " [0.00249236]]\n",
      "1300 0.69314736 [[0.00172365]\n",
      " [0.00168708]]\n",
      "1400 0.6931473 [[0.00116085]\n",
      " [0.0011413 ]]\n",
      "1500 0.69314724 [[0.00078216]\n",
      " [0.00077172]]\n",
      "1600 0.6931472 [[0.00052723]\n",
      " [0.00052164]]\n",
      "1700 0.6931472 [[0.00035547]\n",
      " [0.00035249]]\n",
      "1800 0.6931472 [[0.00023972]\n",
      " [0.00023812]]\n",
      "1900 0.6931472 [[0.00016168]\n",
      " [0.00016083]]\n",
      "2000 0.6931472 [[0.00010907]\n",
      " [0.00010861]]\n",
      "2100 0.6931472 [[7.358043e-05]\n",
      " [7.333132e-05]]\n",
      "2200 0.6931472 [[4.964172e-05]\n",
      " [4.951181e-05]]\n",
      "2300 0.6931472 [[3.3487366e-05]\n",
      " [3.3418561e-05]]\n",
      "2400 0.6931472 [[2.2596105e-05]\n",
      " [2.2558590e-05]]\n",
      "2500 0.6931472 [[1.5239404e-05]\n",
      " [1.5218278e-05]]\n",
      "2600 0.6931472 [[1.0275827e-05]\n",
      " [1.0263642e-05]]\n",
      "2700 0.69314724 [[6.943930e-06]\n",
      " [6.934726e-06]]\n",
      "2800 0.6931472 [[4.680444e-06]\n",
      " [4.675710e-06]]\n",
      "2900 0.6931472 [[3.1351899e-06]\n",
      " [3.1349266e-06]]\n",
      "3000 0.6931472 [[2.1353187e-06]\n",
      " [2.1350554e-06]]\n",
      "3100 0.6931472 [[1.4334730e-06]\n",
      " [1.4332097e-06]]\n",
      "3200 0.6931472 [[9.625927e-07]\n",
      " [9.623294e-07]]\n",
      "3300 0.6931471 [[6.288061e-07]\n",
      " [6.285428e-07]]\n",
      "3400 0.6931472 [[4.3807174e-07]\n",
      " [4.3780844e-07]]\n",
      "3500 0.6931472 [[2.8905956e-07]\n",
      " [2.8879626e-07]]\n",
      "3600 0.6931472 [[1.892214e-07]\n",
      " [1.889581e-07]]\n",
      "3700 0.6931472 [[1.4302762e-07]\n",
      " [1.4276432e-07]]\n",
      "3800 0.6931472 [[1.1918568e-07]\n",
      " [1.1892238e-07]]\n",
      "3900 0.6931472 [[9.385373e-08]\n",
      " [9.359043e-08]]\n",
      "4000 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4100 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4200 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4300 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4400 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4500 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4600 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4700 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4800 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "4900 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5000 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5100 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5200 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5300 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5400 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5500 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5600 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5700 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5800 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "5900 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6000 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6100 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6200 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6300 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6400 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6500 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6600 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6700 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6800 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "6900 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7000 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7100 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7200 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7300 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7400 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7500 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7600 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7700 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7800 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "7900 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8000 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8100 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8200 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8300 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8400 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8500 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8600 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8700 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8800 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "8900 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9000 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9100 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9200 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9300 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9400 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9500 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9600 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9700 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9800 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "9900 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "10000 0.6931472 [[8.789327e-08]\n",
      " [8.762997e-08]]\n",
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\") \n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val, w_val = sess.run(\n",
    "                  [train, cost, W], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val, w_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run(\n",
    "              [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # XOR with NN(Accuracy=100%)\n",
    "#### 위의 코드와 달라진 점은 여러 유닛을 사용했다는 점뿐!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3039298\n",
      "100 0.6936542\n",
      "200 0.69290876\n",
      "300 0.6928032\n",
      "400 0.69267625\n",
      "500 0.69252\n",
      "600 0.6923247\n",
      "700 0.69207656\n",
      "800 0.6917571\n",
      "900 0.69133985\n",
      "1000 0.6907882\n",
      "1100 0.69005084\n",
      "1200 0.689057\n",
      "1300 0.6877116\n",
      "1400 0.6858918\n",
      "1500 0.6834474\n",
      "1600 0.6802071\n",
      "1700 0.6759876\n",
      "1800 0.6706024\n",
      "1900 0.6638644\n",
      "2000 0.6555872\n",
      "2100 0.6455984\n",
      "2200 0.63377607\n",
      "2300 0.6200977\n",
      "2400 0.6046678\n",
      "2500 0.5876817\n",
      "2600 0.5693193\n",
      "2700 0.5496069\n",
      "2800 0.5283127\n",
      "2900 0.5049432\n",
      "3000 0.47891197\n",
      "3100 0.44988436\n",
      "3200 0.4181076\n",
      "3300 0.38445026\n",
      "3400 0.35014117\n",
      "3500 0.31644624\n",
      "3600 0.2844465\n",
      "3700 0.25491923\n",
      "3800 0.2283002\n",
      "3900 0.20471692\n",
      "4000 0.18406773\n",
      "4100 0.16611235\n",
      "4200 0.15054817\n",
      "4300 0.13706076\n",
      "4400 0.12535307\n",
      "4500 0.11515959\n",
      "4600 0.106250495\n",
      "4700 0.09843028\n",
      "4800 0.0915346\n",
      "4900 0.08542625\n",
      "5000 0.079990596\n",
      "5100 0.075132236\n",
      "5200 0.07077117\n",
      "5300 0.06684053\n",
      "5400 0.06328408\n",
      "5500 0.060054258\n",
      "5600 0.057110824\n",
      "5700 0.054419566\n",
      "5800 0.0519511\n",
      "5900 0.049680408\n",
      "6000 0.047585838\n",
      "6100 0.0456485\n",
      "6200 0.04385235\n",
      "6300 0.042183056\n",
      "6400 0.040628225\n",
      "6500 0.039176974\n",
      "6600 0.03781969\n",
      "6700 0.03654793\n",
      "6800 0.03535404\n",
      "6900 0.034231402\n",
      "7000 0.033174127\n",
      "7100 0.032176726\n",
      "7200 0.031234512\n",
      "7300 0.030343145\n",
      "7400 0.029498719\n",
      "7500 0.028697763\n",
      "7600 0.027937133\n",
      "7700 0.027213924\n",
      "7800 0.026525488\n",
      "7900 0.025869511\n",
      "8000 0.025243806\n",
      "8100 0.024646297\n",
      "8200 0.024075205\n",
      "8300 0.023528928\n",
      "8400 0.02300587\n",
      "8500 0.022504618\n",
      "8600 0.022023892\n",
      "8700 0.021562532\n",
      "8800 0.02111928\n",
      "8900 0.020693183\n",
      "9000 0.020283315\n",
      "9100 0.019888798\n",
      "9200 0.019508772\n",
      "9300 0.019142445\n",
      "9400 0.018789211\n",
      "9500 0.018448222\n",
      "9600 0.018119037\n",
      "9700 0.01780098\n",
      "9800 0.017493475\n",
      "9900 0.017196104\n",
      "10000 0.016908344\n",
      "\n",
      "Hypothesis:\n",
      "[[0.01368037]\n",
      " [0.9816905 ]\n",
      " [0.9817343 ]\n",
      " [0.01679075]] \n",
      "Predicted:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
